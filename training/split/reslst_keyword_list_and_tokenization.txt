# ********* - RESLST (41118-41373 / $A09E-$A19D): list of BASIC reserved keywords in token order (tokens 128..202). Describes storage format (ASCII with bit7 set on last letter to mark end) and role in tokenizing input and LISTing programs. Also enumerates some miscellaneous keywords and their token numbers (TAB(, TO, FN, SPC(, THEN, NOT, STEP).

41118-41373   $A09E-$A19D    RESLST
List of Keywords

This table contains a complete list of the reserved BASIC keywords
(those combinations of ASCII text characters that cause BASIC to do
something).  The ASCII text characters of these words are stored in
token number order.  Bit #7 of the last letter of each word is set to
indicate the end of the word (the last letter has 128 added to its
true ASCII value).

When the BASIC program text is stored, this list of words is used to
reduce any keywords to a single-byte value called a token.  The
command PRINT, for example, is not stored in a program as five ASCII
bytes, but rather as the single token 153 ($99).

When the BASIC program is listed, this table is used to convert these
tokens back to ASCII text.  The entries in this table consist of the
following:

1.  The statements found in STMDSP at 40972 ($A00C), in the token
number order indicated (token numbers 128-162).

2.  Some miscellaneous keywords which never begin a BASIC statement:

Token #    Keyword
162 $A3    TAB(
164 $A4    TO
165 $A5    FN
166 $A6    SPC(
167 $A7    THEN
168 $A8    NOT
169 $A9    STEP

3.  The math operators found in OPTAB at 41088 ($A080), in the token
number order indicated (token numbers 170-179).

4.  The functions found in FUNDSP at 41042 ($A052), in the token
number order indicated (token numbers 182-202).

5.  The word GO (token number 203 ($CB)).  This word was added to the
table to make the statement GO TO legal, to afford some compatibility
with the very first PET BASIC, which allowed spaces within keywords.


---
Additional information can be found by searching:
- "crunch_tokenize_line" which expands on CRUNCH routine consults this keyword table when tokenizing input lines
